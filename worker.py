# worker.py
import logging
import asyncio
import json
import os
import subprocess
from pathlib import Path

# --- Конфигурация ---
QUEUE_DIR_PATH = os.getenv("QUEUE_DIR", "rosreestr_queue")
QUEUE_DIR = Path(QUEUE_DIR_PATH)
OUTPUT_DIR_PATH = os.getenv("OUTPUT_DIR", "output")
OUTPUT_DIR = Path(OUTPUT_DIR_PATH)

# Данные прокси провайдера
PROXY_HOST = os.getenv("PROXY_HOST")
PROXY_PORT = os.getenv("PROXY_PORT")
PROXY_USER = os.getenv("PROXY_USER")
PROXY_PASS = os.getenv("PROXY_PASS")

# Выбор провайдера: 'pynspd' (по умолчанию) или 'rosreestr2coord'
PROVIDER = os.getenv("ROSREESTR_PROVIDER", "pynspd").lower()

logging.basicConfig(level=logging.INFO, format='%(asctime)s - WORKER - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Настройка прокси глобально для процесса
if PROXY_HOST and PROXY_PORT:
    proxy_url = f"http://{PROXY_HOST}:{PROXY_PORT}"
    if PROXY_USER and PROXY_PASS:
        proxy_url = f"http://{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}"
    
    os.environ["HTTP_PROXY"] = proxy_url
    os.environ["HTTPS_PROXY"] = proxy_url
    logger.info(f"Proxy configured: {PROXY_HOST}:{PROXY_PORT}")

# --- Логика для pynspd ---
async def process_with_pynspd(cadastral_number, tmp_path):
    from pynspd import AsyncNspd
    
    logger.info(f"Запрос через PyNSPD для {cadastral_number}")
    
    async with AsyncNspd() as nspd:
        # Ищем объект. Если нужно искать ОКС, логику можно усложнить
        features_list = await nspd.search(cadastral_number)
    
        # Проверяем, что список не пуст
        if not features_list:
            # Пробуем универсальный поиск, если участки не найдены
            logger.info("Участок не найден (список пуст), пробуем универсальный поиск...")
            async with AsyncNspd() as nspd:
                features_list = await nspd.search(cadastral_number)
    
    if not features_list:
        return "not_found"

    # Берем ПЕРВЫЙ найденный объект
    feature = features_list[0]
    
    # Сериализация результата (pydantic model -> dict)
    if hasattr(feature, 'model_dump'):
        data = feature.model_dump()
    else:
        # Если вдруг это обычный словарь, а не Pydantic модель
        data = feature if isinstance(feature, dict) else feature.dict()

    with open(tmp_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, default=str)
        
    return "success"

# --- Логика для rosreestr2coord ---
async def process_with_rosreestr2coord(cadastral_number, tmp_path):
    logger.info(f"Запуск subprocess rosreestr2coord для {cadastral_number}")
    
    # Библиотека rosreestr2coord сама формирует имя файла, поэтому нам нужно
    # позволить ей создать файл, а потом найти его и переименовать в tmp_path
    
    # Запускаем в отдельном потоке, чтобы не блокировать event loop
    def run_sync():
        cmd = f'python -m rosreestr2coord -c {cadastral_number}'
        # Прокси берутся из os.environ, который мы настроили выше
        return subprocess.run(
            cmd, shell=True, capture_output=True, text=True, encoding='utf-8', env=os.environ
        )

    result = await asyncio.to_thread(run_sync)
    output_text = (result.stdout + result.stderr).lower()

    if "403" in output_text and "forbidden" in output_text:
        return "forbidden"
    
    if "nothing found" in output_text or "не найдено" in output_text:
        return "not_found"

    # Ищем файл, который создала библиотека (обычно в текущей папке или output/geojson)
    # Имя файла обычно: 77_05_0001005_19.geojson
    generated_name = cadastral_number.replace(":", "_") + ".geojson"
    # Библиотека по умолчанию кладет в ./output/geojson/ если запускается из корня
    # Но так как мы не знаем CWD наверняка, поищем в вероятных местах
    possible_paths = [
        Path("output/geojson") / generated_name,
        Path("geojson") / generated_name,
        Path(".") / generated_name,
        tmp_path.parent / generated_name
    ]
    
    found_file = None
    for p in possible_paths:
        if p.exists():
            found_file = p
            break
            
    if not found_file:
        logger.error(f"rosreestr2coord отработал, но файл не найден. Log: {result.stderr}")
        raise Exception("File not generated by legacy tool")
        
    # Перемещаем файл на место временного файла (унификация)
    found_file.replace(tmp_path)
    
    return "success"

# --- Основной процессор задач ---
async def process_task(task_file: Path):
    task_id = task_file.stem
    
    # Файлы-сигналы
    result_error_file = QUEUE_DIR / f"{task_id}.error"
    result_notfound_file = QUEUE_DIR / f"{task_id}.not_found"
    result_forbidden_file = QUEUE_DIR / f"{task_id}.forbidden"

    try:
        with open(task_file, 'r', encoding='utf-8') as f:
            cadastral_number = f.read().strip()

        safe_filename = cadastral_number.replace(":", "_")
        geojson_tmp = OUTPUT_DIR / "geojson" / f"{safe_filename}.geojson.tmp"
        geojson_final = OUTPUT_DIR / "geojson" / f"{safe_filename}.geojson"

        status = None
        
        # ВЫБОР СТРАТЕГИИ
        try:
            if PROVIDER == "rosreestr2coord":
                status = await process_with_rosreestr2coord(cadastral_number, geojson_tmp)
            else:
                status = await process_with_pynspd(cadastral_number, geojson_tmp)
        except Exception as e_inner:
            # Ловим специфичные ошибки библиотек (например 403 от pynspd)
            err_str = str(e_inner).lower()
            if "403" in err_str or "forbidden" in err_str:
                status = "forbidden"
            else:
                raise e_inner

        # Обработка статусов
        if status == "forbidden":
            logger.warning(f"Task {task_id}: 403 Forbidden ({PROVIDER})")
            result_forbidden_file.touch()
        elif status == "not_found":
            logger.warning(f"Task {task_id}: Not found ({PROVIDER})")
            result_notfound_file.touch()
        elif status == "success":
            # Финализируем файл
            if geojson_tmp.exists():
                geojson_tmp.rename(geojson_final)
                logger.info(f"Task {task_id}: Успех. Файл сохранен.")
            else:
                raise Exception("Статус success, но временный файл отсутствует")
        
    except Exception as e:
        logger.error(f"Task {task_id} Error: {e}")
        with open(result_error_file, 'w', encoding='utf-8') as f:
            json.dump({"error": str(e)}, f, ensure_ascii=False)
            
    finally:
        if task_file.exists():
            os.remove(task_file)

async def main():
    logger.info(f"Воркер запущен. Провайдер: {PROVIDER.upper()}")
    (OUTPUT_DIR / "geojson").mkdir(parents=True, exist_ok=True)
    
    processed_tasks = set()
    
    while True:
        try:
            task_files = list(QUEUE_DIR.glob('*.task'))
            if not task_files:
                await asyncio.sleep(0.5)
                continue

            for task_file in task_files:
                if task_file.name not in processed_tasks:
                    processed_tasks.add(task_file.name)
                    await process_task(task_file)
                    processed_tasks.remove(task_file.name)
        except Exception as e:
            logger.error(f"Loop error: {e}")
            await asyncio.sleep(1)

if __name__ == "__main__":
    asyncio.run(main())